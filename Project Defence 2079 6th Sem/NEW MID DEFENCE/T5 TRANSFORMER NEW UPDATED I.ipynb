{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:16:52.965234Z",
     "iopub.status.busy": "2023-02-02T09:16:52.963996Z",
     "iopub.status.idle": "2023-02-02T09:16:52.972605Z",
     "shell.execute_reply": "2023-02-02T09:16:52.971263Z",
     "shell.execute_reply.started": "2023-02-02T09:16:52.965179Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:16:53.000989Z",
     "iopub.status.busy": "2023-02-02T09:16:53.000665Z",
     "iopub.status.idle": "2023-02-02T09:16:53.005805Z",
     "shell.execute_reply": "2023-02-02T09:16:53.004706Z",
     "shell.execute_reply.started": "2023-02-02T09:16:53.000960Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! wget https://zenodo.org/record/3628775/files/c-corpus.tar.gz?download=1\n",
    "# ! tar -xzf \"/kaggle/working/c-corpus.tar.gz?download=1\"\n",
    "# ! rm /kaggle/working/c-corpus.tar.gz?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-02T09:16:53.034524Z",
     "iopub.status.busy": "2023-02-02T09:16:53.034045Z",
     "iopub.status.idle": "2023-02-02T09:17:13.289701Z",
     "shell.execute_reply": "2023-02-02T09:17:13.288356Z",
     "shell.execute_reply.started": "2023-02-02T09:16:53.034496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.10.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install datasets\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration # RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:13.298443Z",
     "iopub.status.busy": "2023-02-02T09:17:13.295734Z",
     "iopub.status.idle": "2023-02-02T09:17:13.306270Z",
     "shell.execute_reply": "2023-02-02T09:17:13.305073Z",
     "shell.execute_reply.started": "2023-02-02T09:17:13.298399Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"CORRECT\", 1: \"BUGGY\"}\n",
    "label2id = {\"CORRECT\": 0, \"BUGGY\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:13.314006Z",
     "iopub.status.busy": "2023-02-02T09:17:13.311627Z",
     "iopub.status.idle": "2023-02-02T09:17:16.164137Z",
     "shell.execute_reply": "2023-02-02T09:17:16.162661Z",
     "shell.execute_reply.started": "2023-02-02T09:17:13.313970Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/dipudl/codet5-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/ed7e409e6ad247e09a2ca8a19dc9e58d74cb30795f408bcb716cb6756f54b76d.9a35ae57ce66b3a375abfa9a6a2fa53dcd2cd361db8e6478877f08569f69b771\n",
      "loading file https://huggingface.co/dipudl/codet5-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/1f727ef4e0afebcfcf86fe431abd086875e1d80f1da0e5fc0cc33e4077faf0a9.1c2821a0b9a2f62bbeacf7ba0b4c2b2b4dd6f63645fe6681015af90a376d90a1\n",
      "loading file https://huggingface.co/dipudl/codet5-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/792db69f7307dc6c44be61f902366e9c9ca3d6f8daa189f150e4a407f15a0db0.e2e19d1cfdd164eb1be4cf51c10f0fd5abbc13d2d1ab3839ca28f7dc2e392a87\n",
      "loading file https://huggingface.co/dipudl/codet5-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/dipudl/codet5-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/ab59879daf5d010a005747a60ee1f4865d1d50b7c7a741b50da31afa0f72fb79.b96745c096b3a4fc6596ce01a6556b16c22ddd0b11968d6d04fd7d47ec12b195\n",
      "loading file https://huggingface.co/dipudl/codet5-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/eb2c27e70b2b4707ef4838c5dd1c2c6987c6eadba9a91e1b1292328b7e3586c3.117f864c3368b518c7e59612994c69b268c7b01f3d0a5ffcc063497c0f0aebc7\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"CORRECT\",\n",
      "    \"1\": \"BUGGY\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"BUGGY\": 1,\n",
      "    \"CORRECT\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('dipudl/codet5-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased',\n",
    "                                                           num_labels=2,\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:16.168407Z",
     "iopub.status.busy": "2023-02-02T09:17:16.167473Z",
     "iopub.status.idle": "2023-02-02T09:17:16.176422Z",
     "shell.execute_reply": "2023-02-02T09:17:16.175190Z",
     "shell.execute_reply.started": "2023-02-02T09:17:16.168359Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_tokenizer_training_corpus():\n",
    "    total = 0\n",
    "    for root, dirs, files in os.walk(\"/kaggle/working/cleaned\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".c\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    content = str(f.read())\n",
    "                    total += 1\n",
    "                    if total % 10000 == 0:\n",
    "                        print(total)\n",
    "                    yield [content]\n",
    "                        \n",
    "#     dataset = train_dataset\n",
    "#     for start_idx in range(0, len(dataset), 1000):\n",
    "#         samples = dataset[start_idx : start_idx + 1000]\n",
    "#         yield samples[\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:16.178965Z",
     "iopub.status.busy": "2023-02-02T09:17:16.178153Z",
     "iopub.status.idle": "2023-02-02T09:17:16.193997Z",
     "shell.execute_reply": "2023-02-02T09:17:16.192917Z",
     "shell.execute_reply.started": "2023-02-02T09:17:16.178921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_tokenizer_training_corpus at 0x7fa224de6050>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_training_corpus = get_tokenizer_training_corpus()\n",
    "tokenizer_training_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:16.196759Z",
     "iopub.status.busy": "2023-02-02T09:17:16.195519Z",
     "iopub.status.idle": "2023-02-02T09:17:16.207310Z",
     "shell.execute_reply": "2023-02-02T09:17:16.206113Z",
     "shell.execute_reply.started": "2023-02-02T09:17:16.196720Z"
    }
   },
   "outputs": [],
   "source": [
    "# fine_tuned_tokenizer = tokenizer.train_new_from_iterator(tokenizer_training_corpus, vocab_size=20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:16.208962Z",
     "iopub.status.busy": "2023-02-02T09:17:16.208669Z",
     "iopub.status.idle": "2023-02-02T09:17:27.511801Z",
     "shell.execute_reply": "2023-02-02T09:17:27.510361Z",
     "shell.execute_reply.started": "2023-02-02T09:17:16.208929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token(YOUR_HUGGING_FACE_TOKEN_HERE)\"\n",
    "\n",
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.515084Z",
     "iopub.status.busy": "2023-02-02T09:17:27.514637Z",
     "iopub.status.idle": "2023-02-02T09:17:27.520057Z",
     "shell.execute_reply": "2023-02-02T09:17:27.518685Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.515039Z"
    }
   },
   "outputs": [],
   "source": [
    "# fine_tuned_tokenizer.save_pretrained(\"codet5-base\")\n",
    "# fine_tuned_tokenizer.push_to_hub(\"codet5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.523180Z",
     "iopub.status.busy": "2023-02-02T09:17:27.522254Z",
     "iopub.status.idle": "2023-02-02T09:17:27.531072Z",
     "shell.execute_reply": "2023-02-02T09:17:27.529973Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.523141Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('dipudl/codet5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.536733Z",
     "iopub.status.busy": "2023-02-02T09:17:27.536435Z",
     "iopub.status.idle": "2023-02-02T09:17:27.705872Z",
     "shell.execute_reply": "2023-02-02T09:17:27.704792Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.536705Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/function-swap-samples-178k/function_swap_samples.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.708331Z",
     "iopub.status.busy": "2023-02-02T09:17:27.707337Z",
     "iopub.status.idle": "2023-02-02T09:17:27.728464Z",
     "shell.execute_reply": "2023-02-02T09:17:27.727581Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.708289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function_name</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg_type</th>\n",
       "      <th>param1</th>\n",
       "      <th>param2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x3000</td>\n",
       "      <td>0x2000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x2000</td>\n",
       "      <td>0x3000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x7000</td>\n",
       "      <td>0x5000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x5000</td>\n",
       "      <td>0x7000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo0000</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>fract2x16</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178275</th>\n",
       "      <td>strstr</td>\n",
       "      <td>libname</td>\n",
       "      <td>package:</td>\n",
       "      <td>char *</td>\n",
       "      <td>__haystack</td>\n",
       "      <td>__needle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178276</th>\n",
       "      <td>strstr</td>\n",
       "      <td>package:</td>\n",
       "      <td>libname</td>\n",
       "      <td>char *</td>\n",
       "      <td>__haystack</td>\n",
       "      <td>__needle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178277</th>\n",
       "      <td>fopen</td>\n",
       "      <td>fn</td>\n",
       "      <td>w</td>\n",
       "      <td>FILE *</td>\n",
       "      <td>__filename</td>\n",
       "      <td>__modes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178278</th>\n",
       "      <td>fopen</td>\n",
       "      <td>w</td>\n",
       "      <td>fn</td>\n",
       "      <td>FILE *</td>\n",
       "      <td>__filename</td>\n",
       "      <td>__modes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178279</th>\n",
       "      <td>REprintf</td>\n",
       "      <td>Error: Could not write to '%s'. [vimcom]\\n</td>\n",
       "      <td>fn</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178280 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      function_name  \\\n",
       "0       __builtin_bfin_compose_2x16   \n",
       "1       __builtin_bfin_compose_2x16   \n",
       "2       __builtin_bfin_compose_2x16   \n",
       "3       __builtin_bfin_compose_2x16   \n",
       "4                           foo0000   \n",
       "...                             ...   \n",
       "178275                       strstr   \n",
       "178276                       strstr   \n",
       "178277                        fopen   \n",
       "178278                        fopen   \n",
       "178279                     REprintf   \n",
       "\n",
       "                                              arg1      arg2   arg_type  \\\n",
       "0                                           0x3000    0x2000        int   \n",
       "1                                           0x2000    0x3000        int   \n",
       "2                                           0x7000    0x5000        int   \n",
       "3                                           0x5000    0x7000        int   \n",
       "4                                                a         b  fract2x16   \n",
       "...                                            ...       ...        ...   \n",
       "178275                                     libname  package:     char *   \n",
       "178276                                    package:   libname     char *   \n",
       "178277                                          fn         w     FILE *   \n",
       "178278                                           w        fn     FILE *   \n",
       "178279  Error: Could not write to '%s'. [vimcom]\\n        fn        int   \n",
       "\n",
       "            param1    param2  labels  \n",
       "0              NaN       NaN       0  \n",
       "1              NaN       NaN       1  \n",
       "2              NaN       NaN       0  \n",
       "3              NaN       NaN       1  \n",
       "4                a         b       0  \n",
       "...            ...       ...     ...  \n",
       "178275  __haystack  __needle       0  \n",
       "178276  __haystack  __needle       1  \n",
       "178277  __filename   __modes       0  \n",
       "178278  __filename   __modes       1  \n",
       "178279         NaN       NaN       0  \n",
       "\n",
       "[178280 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.731597Z",
     "iopub.status.busy": "2023-02-02T09:17:27.730815Z",
     "iopub.status.idle": "2023-02-02T09:17:27.834673Z",
     "shell.execute_reply": "2023-02-02T09:17:27.833536Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.731568Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.837167Z",
     "iopub.status.busy": "2023-02-02T09:17:27.836168Z",
     "iopub.status.idle": "2023-02-02T09:17:27.855157Z",
     "shell.execute_reply": "2023-02-02T09:17:27.854078Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.837129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function_name</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg_type</th>\n",
       "      <th>param1</th>\n",
       "      <th>param2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x3000</td>\n",
       "      <td>0x2000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x2000</td>\n",
       "      <td>0x3000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x7000</td>\n",
       "      <td>0x5000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__builtin_bfin_compose_2x16</td>\n",
       "      <td>0x5000</td>\n",
       "      <td>0x7000</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo0000</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>fract2x16</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83839</th>\n",
       "      <td>REprintf</td>\n",
       "      <td>rep</td>\n",
       "      <td>VimCom Sent: %s\\n</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83840</th>\n",
       "      <td>strcmp</td>\n",
       "      <td>name</td>\n",
       "      <td>table</td>\n",
       "      <td>int</td>\n",
       "      <td>__s1</td>\n",
       "      <td>__s2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83841</th>\n",
       "      <td>strcmp</td>\n",
       "      <td>table</td>\n",
       "      <td>name</td>\n",
       "      <td>int</td>\n",
       "      <td>__s1</td>\n",
       "      <td>__s2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83842</th>\n",
       "      <td>fopen</td>\n",
       "      <td>.live</td>\n",
       "      <td>w</td>\n",
       "      <td>FILE *</td>\n",
       "      <td>__filename</td>\n",
       "      <td>__modes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83843</th>\n",
       "      <td>fopen</td>\n",
       "      <td>w</td>\n",
       "      <td>.live</td>\n",
       "      <td>FILE *</td>\n",
       "      <td>__filename</td>\n",
       "      <td>__modes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83844 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     function_name    arg1               arg2   arg_type  \\\n",
       "0      __builtin_bfin_compose_2x16  0x3000             0x2000        int   \n",
       "1      __builtin_bfin_compose_2x16  0x2000             0x3000        int   \n",
       "2      __builtin_bfin_compose_2x16  0x7000             0x5000        int   \n",
       "3      __builtin_bfin_compose_2x16  0x5000             0x7000        int   \n",
       "4                          foo0000       a                  b  fract2x16   \n",
       "...                            ...     ...                ...        ...   \n",
       "83839                     REprintf     rep  VimCom Sent: %s\\n        int   \n",
       "83840                       strcmp    name              table        int   \n",
       "83841                       strcmp   table               name        int   \n",
       "83842                        fopen   .live                  w     FILE *   \n",
       "83843                        fopen       w              .live     FILE *   \n",
       "\n",
       "           param1   param2  labels  \n",
       "0             NaN      NaN       0  \n",
       "1             NaN      NaN       1  \n",
       "2             NaN      NaN       0  \n",
       "3             NaN      NaN       1  \n",
       "4               a        b       0  \n",
       "...           ...      ...     ...  \n",
       "83839         NaN      NaN       1  \n",
       "83840        __s1     __s2       0  \n",
       "83841        __s1     __s2       1  \n",
       "83842  __filename  __modes       0  \n",
       "83843  __filename  __modes       1  \n",
       "\n",
       "[83844 rows x 7 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.858125Z",
     "iopub.status.busy": "2023-02-02T09:17:27.857569Z",
     "iopub.status.idle": "2023-02-02T09:17:27.886462Z",
     "shell.execute_reply": "2023-02-02T09:17:27.885176Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.858089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function_name      288\n",
       "arg1               520\n",
       "arg2               520\n",
       "arg_type             0\n",
       "param1           52284\n",
       "param2           52276\n",
       "labels               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.888821Z",
     "iopub.status.busy": "2023-02-02T09:17:27.888077Z",
     "iopub.status.idle": "2023-02-02T09:17:27.925158Z",
     "shell.execute_reply": "2023-02-02T09:17:27.924275Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.888779Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['function_name'] = df['function_name'].fillna('[UNK]')\n",
    "# df['arg1']=df['arg1'].fillna('[UNK]')\n",
    "# df['arg2']=df['arg2'].fillna('[UNK]')\n",
    "# df['arg_type']=df['arg_type'].fillna('[UNK]')\n",
    "# df['param1']=df['param1'].fillna('[UNK]')\n",
    "# df['param2']=df['param2'].fillna('[UNK]')\n",
    "\n",
    "df['function_name'] = df['function_name'].fillna('')\n",
    "df['arg1']=df['arg1'].fillna('')\n",
    "df['arg2']=df['arg2'].fillna('')\n",
    "df['arg_type']=df['arg_type'].fillna('')\n",
    "df['param1']=df['param1'].fillna('')\n",
    "df['param2']=df['param2'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.926980Z",
     "iopub.status.busy": "2023-02-02T09:17:27.926458Z",
     "iopub.status.idle": "2023-02-02T09:17:27.955069Z",
     "shell.execute_reply": "2023-02-02T09:17:27.954147Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.926944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function_name    0\n",
       "arg1             0\n",
       "arg2             0\n",
       "arg_type         0\n",
       "param1           0\n",
       "param2           0\n",
       "labels           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:27.958439Z",
     "iopub.status.busy": "2023-02-02T09:17:27.958165Z",
     "iopub.status.idle": "2023-02-02T09:17:28.034045Z",
     "shell.execute_reply": "2023-02-02T09:17:28.033066Z",
     "shell.execute_reply.started": "2023-02-02T09:17:27.958414Z"
    }
   },
   "outputs": [],
   "source": [
    "df['full_text'] = df['function_name'] + ' [SEP] '+ df['arg1'] + ' [SEP] '+ df['arg2'] + ' [SEP] '+ df['arg_type'] + ' [SEP] '+ df['param1'] + ' [SEP] ' + df['param2']\n",
    "# df['full_text'] = df['function_name'] + ' '+ df['arg1'] + ' '+ df['arg2'] + ' '+ df['arg_type'] + ' '+ df['param1'] + ' ' + df['param2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.036186Z",
     "iopub.status.busy": "2023-02-02T09:17:28.035393Z",
     "iopub.status.idle": "2023-02-02T09:17:28.061284Z",
     "shell.execute_reply": "2023-02-02T09:17:28.060085Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.036146Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['function_name','arg1','arg2','arg_type','param1','param2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.063624Z",
     "iopub.status.busy": "2023-02-02T09:17:28.062842Z",
     "iopub.status.idle": "2023-02-02T09:17:28.075464Z",
     "shell.execute_reply": "2023-02-02T09:17:28.074243Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.063585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>__builtin_bfin_compose_2x16 [SEP] 0x3000 [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>__builtin_bfin_compose_2x16 [SEP] 0x2000 [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>__builtin_bfin_compose_2x16 [SEP] 0x7000 [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>__builtin_bfin_compose_2x16 [SEP] 0x5000 [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>foo0000 [SEP] a [SEP] b [SEP] fract2x16 [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83839</th>\n",
       "      <td>1</td>\n",
       "      <td>REprintf [SEP] rep [SEP] VimCom Sent: %s\\n [SE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83840</th>\n",
       "      <td>0</td>\n",
       "      <td>strcmp [SEP] name [SEP] table [SEP] int [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83841</th>\n",
       "      <td>1</td>\n",
       "      <td>strcmp [SEP] table [SEP] name [SEP] int [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83842</th>\n",
       "      <td>0</td>\n",
       "      <td>fopen [SEP] .live [SEP] w [SEP] FILE * [SEP] _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83843</th>\n",
       "      <td>1</td>\n",
       "      <td>fopen [SEP] w [SEP] .live [SEP] FILE * [SEP] _...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83844 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                          full_text\n",
       "0           0  __builtin_bfin_compose_2x16 [SEP] 0x3000 [SEP]...\n",
       "1           1  __builtin_bfin_compose_2x16 [SEP] 0x2000 [SEP]...\n",
       "2           0  __builtin_bfin_compose_2x16 [SEP] 0x7000 [SEP]...\n",
       "3           1  __builtin_bfin_compose_2x16 [SEP] 0x5000 [SEP]...\n",
       "4           0  foo0000 [SEP] a [SEP] b [SEP] fract2x16 [SEP] ...\n",
       "...       ...                                                ...\n",
       "83839       1  REprintf [SEP] rep [SEP] VimCom Sent: %s\\n [SE...\n",
       "83840       0  strcmp [SEP] name [SEP] table [SEP] int [SEP] ...\n",
       "83841       1  strcmp [SEP] table [SEP] name [SEP] int [SEP] ...\n",
       "83842       0  fopen [SEP] .live [SEP] w [SEP] FILE * [SEP] _...\n",
       "83843       1  fopen [SEP] w [SEP] .live [SEP] FILE * [SEP] _...\n",
       "\n",
       "[83844 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.077768Z",
     "iopub.status.busy": "2023-02-02T09:17:28.077418Z",
     "iopub.status.idle": "2023-02-02T09:17:28.083732Z",
     "shell.execute_reply": "2023-02-02T09:17:28.082415Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.077734Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples[\"full_text\"], truncation=True, max_length=100, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.085589Z",
     "iopub.status.busy": "2023-02-02T09:17:28.085077Z",
     "iopub.status.idle": "2023-02-02T09:17:28.110929Z",
     "shell.execute_reply": "2023-02-02T09:17:28.110005Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.085551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PsychMatch [SEP] TextEncodingLocale [SEP] pref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>strcasecmp [SEP] name_type [SEP] hostbased-ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>strcmp [SEP] FUNSMRY [SEP] ext [SEP] int [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>strstr [SEP] .c [SEP] output_file_name [SEP] c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>gg_fopen [SEP] buf [SEP] w [SEP] FILE * [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83839</th>\n",
       "      <td>1</td>\n",
       "      <td>test [SEP] domain.com [SEP] example.com, *.dom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83840</th>\n",
       "      <td>0</td>\n",
       "      <td>strcmp [SEP] * [SEP] -descert [SEP] int [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83841</th>\n",
       "      <td>0</td>\n",
       "      <td>strcasecmp [SEP] in [SEP] q931 [SEP] int [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83842</th>\n",
       "      <td>0</td>\n",
       "      <td>__builtin_isunordered [SEP] __builtin_nan [SEP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83843</th>\n",
       "      <td>1</td>\n",
       "      <td>sdscat [SEP] sentinel, [SEP] flags [SEP] int [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83844 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                          full_text\n",
       "0           1  PsychMatch [SEP] TextEncodingLocale [SEP] pref...\n",
       "1           1  strcasecmp [SEP] name_type [SEP] hostbased-ser...\n",
       "2           1  strcmp [SEP] FUNSMRY [SEP] ext [SEP] int [SEP]...\n",
       "3           1  strstr [SEP] .c [SEP] output_file_name [SEP] c...\n",
       "4           0  gg_fopen [SEP] buf [SEP] w [SEP] FILE * [SEP] ...\n",
       "...       ...                                                ...\n",
       "83839       1  test [SEP] domain.com [SEP] example.com, *.dom...\n",
       "83840       0  strcmp [SEP] * [SEP] -descert [SEP] int [SEP] ...\n",
       "83841       0  strcasecmp [SEP] in [SEP] q931 [SEP] int [SEP]...\n",
       "83842       0  __builtin_isunordered [SEP] __builtin_nan [SEP...\n",
       "83843       1  sdscat [SEP] sentinel, [SEP] flags [SEP] int [...\n",
       "\n",
       "[83844 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1) # shuffling the dataset\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.113642Z",
     "iopub.status.busy": "2023-02-02T09:17:28.112972Z",
     "iopub.status.idle": "2023-02-02T09:17:28.126798Z",
     "shell.execute_reply": "2023-02-02T09:17:28.125718Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.113604Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.128628Z",
     "iopub.status.busy": "2023-02-02T09:17:28.128248Z",
     "iopub.status.idle": "2023-02-02T09:17:28.141713Z",
     "shell.execute_reply": "2023-02-02T09:17:28.140713Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.128582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80345</th>\n",
       "      <td>1</td>\n",
       "      <td>damroll [SEP] 4 [SEP] 10 [SEP] int [SEP]  [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47067</th>\n",
       "      <td>0</td>\n",
       "      <td>hp3800_calibtransparent [SEP] option [SEP] def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81877</th>\n",
       "      <td>1</td>\n",
       "      <td>strpbrk [SEP]  \\t [SEP] newname [SEP] char * [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>0</td>\n",
       "      <td>warning [SEP] 152 [SEP] n [SEP] int [SEP]  [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47722</th>\n",
       "      <td>1</td>\n",
       "      <td>dssp_error_message [SEP] strerror [SEP] error ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82752</th>\n",
       "      <td>1</td>\n",
       "      <td>strcmp [SEP] request [SEP] type [SEP] int [SEP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68946</th>\n",
       "      <td>0</td>\n",
       "      <td>[SEP] f [SEP] a [SEP] &lt;dependent type&gt; [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73026</th>\n",
       "      <td>1</td>\n",
       "      <td>_rl_rubout_char [SEP] key [SEP] count [SEP] in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34722</th>\n",
       "      <td>0</td>\n",
       "      <td>die [SEP] invalid log-grep regex: %s [SEP] err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50362</th>\n",
       "      <td>0</td>\n",
       "      <td>fopen [SEP] quant_pitch.txt [SEP] wt [SEP] FIL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                          full_text\n",
       "80345       1   damroll [SEP] 4 [SEP] 10 [SEP] int [SEP]  [SEP] \n",
       "47067       0  hp3800_calibtransparent [SEP] option [SEP] def...\n",
       "81877       1  strpbrk [SEP]  \\t [SEP] newname [SEP] char * [...\n",
       "3875        0  warning [SEP] 152 [SEP] n [SEP] int [SEP]  [SEP] \n",
       "47722       1  dssp_error_message [SEP] strerror [SEP] error ...\n",
       "...       ...                                                ...\n",
       "82752       1  strcmp [SEP] request [SEP] type [SEP] int [SEP...\n",
       "68946       0   [SEP] f [SEP] a [SEP] <dependent type> [SEP] ...\n",
       "73026       1  _rl_rubout_char [SEP] key [SEP] count [SEP] in...\n",
       "34722       0  die [SEP] invalid log-grep regex: %s [SEP] err...\n",
       "50362       0  fopen [SEP] quant_pitch.txt [SEP] wt [SEP] FIL...\n",
       "\n",
       "[75459 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.143943Z",
     "iopub.status.busy": "2023-02-02T09:17:28.143267Z",
     "iopub.status.idle": "2023-02-02T09:17:28.154653Z",
     "shell.execute_reply": "2023-02-02T09:17:28.153767Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.143907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77154</th>\n",
       "      <td>1</td>\n",
       "      <td>strcmp [SEP] default [SEP] s [SEP] int [SEP] _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17991</th>\n",
       "      <td>1</td>\n",
       "      <td>TIFFError [SEP] Wrong image parameters; can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>1</td>\n",
       "      <td>__builtin_atan2f [SEP] 0.0 [SEP] - [SEP] float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69119</th>\n",
       "      <td>0</td>\n",
       "      <td>printf [SEP] subfile %s not found\\n [SEP] subf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50626</th>\n",
       "      <td>1</td>\n",
       "      <td>strcmpi [SEP] nobranch [SEP] flag [SEP] int [S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0</td>\n",
       "      <td>dup2 [SEP] ofd [SEP] 1 [SEP] int [SEP] __fd [S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40712</th>\n",
       "      <td>0</td>\n",
       "      <td>printf [SEP] %s [SEP] hdr [SEP] int [SEP]  [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68569</th>\n",
       "      <td>1</td>\n",
       "      <td>w_timeval_compare [SEP] file [SEP] since [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67414</th>\n",
       "      <td>1</td>\n",
       "      <td>strcmp [SEP] action [SEP] param [SEP] int [SEP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63189</th>\n",
       "      <td>0</td>\n",
       "      <td>strcmp [SEP] argv [SEP] iso [SEP] int [SEP] __...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8385 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                          full_text\n",
       "77154       1  strcmp [SEP] default [SEP] s [SEP] int [SEP] _...\n",
       "17991       1  TIFFError [SEP] Wrong image parameters; can't ...\n",
       "15317       1  __builtin_atan2f [SEP] 0.0 [SEP] - [SEP] float...\n",
       "69119       0  printf [SEP] subfile %s not found\\n [SEP] subf...\n",
       "50626       1  strcmpi [SEP] nobranch [SEP] flag [SEP] int [S...\n",
       "...       ...                                                ...\n",
       "1450        0  dup2 [SEP] ofd [SEP] 1 [SEP] int [SEP] __fd [S...\n",
       "40712       0  printf [SEP] %s [SEP] hdr [SEP] int [SEP]  [SEP] \n",
       "68569       1  w_timeval_compare [SEP] file [SEP] since [SEP]...\n",
       "67414       1  strcmp [SEP] action [SEP] param [SEP] int [SEP...\n",
       "63189       0  strcmp [SEP] argv [SEP] iso [SEP] int [SEP] __...\n",
       "\n",
       "[8385 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.156975Z",
     "iopub.status.busy": "2023-02-02T09:17:28.156070Z",
     "iopub.status.idle": "2023-02-02T09:17:28.180883Z",
     "shell.execute_reply": "2023-02-02T09:17:28.180068Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.156827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'full_text', '__index_level_0__'],\n",
       "    num_rows: 75459\n",
       "})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.182424Z",
     "iopub.status.busy": "2023-02-02T09:17:28.182065Z",
     "iopub.status.idle": "2023-02-02T09:17:28.194325Z",
     "shell.execute_reply": "2023-02-02T09:17:28.193212Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.182387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'full_text', '__index_level_0__'],\n",
       "    num_rows: 8385\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:28.196403Z",
     "iopub.status.busy": "2023-02-02T09:17:28.196043Z",
     "iopub.status.idle": "2023-02-02T09:17:35.187064Z",
     "shell.execute_reply": "2023-02-02T09:17:35.185963Z",
     "shell.execute_reply.started": "2023-02-02T09:17:28.196369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b572a6565f4d18be59832e40d7f487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 75000\n",
       "})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_text, batched=True, drop_last_batch=True, remove_columns=[\"full_text\", \"__index_level_0__\"])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:35.193519Z",
     "iopub.status.busy": "2023-02-02T09:17:35.193182Z",
     "iopub.status.idle": "2023-02-02T09:17:35.980788Z",
     "shell.execute_reply": "2023-02-02T09:17:35.979738Z",
     "shell.execute_reply.started": "2023-02-02T09:17:35.193489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4686c96c1f4f465d9f1e0d2b393e3506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(tokenize_text, batched=True, drop_last_batch=True, remove_columns=[\"full_text\", \"__index_level_0__\"])\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:35.983042Z",
     "iopub.status.busy": "2023-02-02T09:17:35.982383Z",
     "iopub.status.idle": "2023-02-02T09:17:35.988980Z",
     "shell.execute_reply": "2023-02-02T09:17:35.987885Z",
     "shell.execute_reply.started": "2023-02-02T09:17:35.982985Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:35.990984Z",
     "iopub.status.busy": "2023-02-02T09:17:35.990534Z",
     "iopub.status.idle": "2023-02-02T09:17:36.017667Z",
     "shell.execute_reply": "2023-02-02T09:17:36.016563Z",
     "shell.execute_reply.started": "2023-02-02T09:17:35.990942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 7500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:36.020315Z",
     "iopub.status.busy": "2023-02-02T09:17:36.019154Z",
     "iopub.status.idle": "2023-02-02T09:17:36.029063Z",
     "shell.execute_reply": "2023-02-02T09:17:36.028332Z",
     "shell.execute_reply.started": "2023-02-02T09:17:36.020271Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "logging_steps = len(train_dataset[\"train\"]) // batch_size\n",
    "output_dir = \"function-arg-swap-model\"\n",
    "training_args = TrainingArguments(output_dir,\n",
    "                                  num_train_epochs=10,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay = 0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  # save_steps=10000,\n",
    "                                  # fp16=True,\n",
    "                                  push_to_hub=False,\n",
    "                                  report_to=\"wandb\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:36.031447Z",
     "iopub.status.busy": "2023-02-02T09:17:36.030730Z",
     "iopub.status.idle": "2023-02-02T09:17:36.123928Z",
     "shell.execute_reply": "2023-02-02T09:17:36.122864Z",
     "shell.execute_reply.started": "2023-02-02T09:17:36.031410Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, DefaultDataCollator\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset[\"train\"],         \n",
    "    eval_dataset=train_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T09:17:36.125987Z",
     "iopub.status.busy": "2023-02-02T09:17:36.125587Z",
     "iopub.status.idle": "2023-02-02T10:19:34.517659Z",
     "shell.execute_reply": "2023-02-02T10:19:34.516321Z",
     "shell.execute_reply.started": "2023-02-02T09:17:36.125946Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 67500\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10550\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230202_091752-40cbsts9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/test-only-team/huggingface/runs/40cbsts9\" target=\"_blank\">function-arg-swap-model</a></strong> to <a href=\"https://wandb.ai/test-only-team/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10550' max='10550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10550/10550 1:01:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.517919</td>\n",
       "      <td>0.722133</td>\n",
       "      <td>0.698844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>0.368466</td>\n",
       "      <td>0.811733</td>\n",
       "      <td>0.795836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>0.326795</td>\n",
       "      <td>0.834533</td>\n",
       "      <td>0.833400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.334577</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.845013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.306111</td>\n",
       "      <td>0.854933</td>\n",
       "      <td>0.849474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.298890</td>\n",
       "      <td>0.864667</td>\n",
       "      <td>0.864214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.297035</td>\n",
       "      <td>0.874800</td>\n",
       "      <td>0.875415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.290025</td>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.874866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.292785</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.874715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.305205</td>\n",
       "      <td>0.878133</td>\n",
       "      <td>0.877611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to function-arg-swap-model/checkpoint-10000\n",
      "Configuration saved in function-arg-swap-model/checkpoint-10000/config.json\n",
      "Model weights saved in function-arg-swap-model/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in function-arg-swap-model/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in function-arg-swap-model/checkpoint-10000/special_tokens_map.json\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7500\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T11:21:21.567694Z",
     "iopub.status.busy": "2023-02-02T11:21:21.567318Z",
     "iopub.status.idle": "2023-02-02T11:21:22.162617Z",
     "shell.execute_reply": "2023-02-02T11:21:22.161660Z",
     "shell.execute_reply.started": "2023-02-02T11:21:21.567656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to codet5-87.7f1-10ep\n",
      "Configuration saved in codet5-87.7f1-10ep/config.json\n",
      "Model weights saved in codet5-87.7f1-10ep/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-87.7f1-10ep/tokenizer_config.json\n",
      "Special tokens file saved in codet5-87.7f1-10ep/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"codet5-87.7f1-10ep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Testing\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T10:25:27.631439Z",
     "iopub.status.busy": "2023-02-02T10:25:27.630219Z",
     "iopub.status.idle": "2023-02-02T10:25:41.444818Z",
     "shell.execute_reply": "2023-02-02T10:25:41.443639Z",
     "shell.execute_reply.started": "2023-02-02T10:25:27.631396Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 8000\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 1:27:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T11:52:22.046639Z",
     "iopub.status.busy": "2023-02-02T11:52:22.046250Z",
     "iopub.status.idle": "2023-02-02T11:52:22.057744Z",
     "shell.execute_reply": "2023-02-02T11:52:22.056381Z",
     "shell.execute_reply.started": "2023-02-02T11:52:22.046606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-1.5262053 ,  1.555742  ],\n",
       "       [-3.6396356 ,  3.778317  ],\n",
       "       [ 0.31872478, -0.5065445 ],\n",
       "       ...,\n",
       "       [ 0.45182976, -0.59455925],\n",
       "       [-3.956964  ,  4.152476  ],\n",
       "       [ 3.6027818 , -3.866059  ]], dtype=float32), label_ids=array([1, 1, 1, ..., 0, 1, 0]), metrics={'test_loss': 0.3309861123561859, 'test_accuracy': 0.868875, 'test_f1': 0.8716819571865444, 'test_runtime': 13.7994, 'test_samples_per_second': 579.735, 'test_steps_per_second': 9.058})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T11:52:41.164808Z",
     "iopub.status.busy": "2023-02-02T11:52:41.164194Z",
     "iopub.status.idle": "2023-02-02T11:52:54.890903Z",
     "shell.execute_reply": "2023-02-02T11:52:54.889667Z",
     "shell.execute_reply.started": "2023-02-02T11:52:41.164764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 8000\n",
      "  Batch size = 64\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T11:56:03.604088Z",
     "iopub.status.busy": "2023-02-02T11:56:03.602876Z",
     "iopub.status.idle": "2023-02-02T11:56:03.618665Z",
     "shell.execute_reply": "2023-02-02T11:56:03.616775Z",
     "shell.execute_reply.started": "2023-02-02T11:56:03.604013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T11:57:40.501921Z",
     "iopub.status.busy": "2023-02-02T11:57:40.501499Z",
     "iopub.status.idle": "2023-02-02T11:57:40.528785Z",
     "shell.execute_reply": "2023-02-02T11:57:40.527588Z",
     "shell.execute_reply.started": "2023-02-02T11:57:40.501887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716819571865444"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predictions, test_dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T11:59:17.069718Z",
     "iopub.status.busy": "2023-02-02T11:59:17.069355Z",
     "iopub.status.idle": "2023-02-02T11:59:17.093965Z",
     "shell.execute_reply": "2023-02-02T11:59:17.092738Z",
     "shell.execute_reply.started": "2023-02-02T11:59:17.069688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[3388  519]\n",
      " [ 530 3563]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(predictions, test_dataset[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T12:18:19.507789Z",
     "iopub.status.busy": "2023-02-02T12:18:19.507419Z",
     "iopub.status.idle": "2023-02-02T12:18:19.767567Z",
     "shell.execute_reply": "2023-02-02T12:18:19.766645Z",
     "shell.execute_reply.started": "2023-02-02T12:18:19.507757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "a = [[3388,519],\n",
    " [530,3563]]\n",
    "\n",
    "# Select Confusion Matrix Size\n",
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "# Select Confusion Matrix Size\n",
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "# Create Confusion Matrix and show percentages\n",
    "b = sns.heatmap(a/np.sum(a), annot=True, fmt='.1%')\n",
    "\n",
    "# Set the Title\n",
    "b.set(title='Confusion Matrix')\n",
    "\n",
    "# Set the Labels\n",
    "b.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "# Display the Confusion Matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Inference\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T11:12:45.915881Z",
     "iopub.status.busy": "2023-02-02T11:12:45.915445Z",
     "iopub.status.idle": "2023-02-02T11:12:47.182475Z",
     "shell.execute_reply": "2023-02-02T11:12:47.181285Z",
     "shell.execute_reply.started": "2023-02-02T11:12:45.915844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "checkpoint-10000\n"
     ]
    }
   ],
   "source": [
    "! ls /kaggle/working/function-arg-swap-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
